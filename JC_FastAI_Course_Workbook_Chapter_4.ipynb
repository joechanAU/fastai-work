{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joechanAU/fastai-work/blob/main/JC_FastAI_Course_Workbook_Chapter_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BAecjIvQ-u7"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66THGb51RIfl"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of MNIST Images Example\n"
      ],
      "metadata": {
        "id": "8QZBRb96sT-v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VJi4LKcRPU7"
      },
      "outputs": [],
      "source": [
        "# Get the MNIST sample dataset\n",
        "path = untar_data(URLs.MNIST_SAMPLE)\n",
        "Path.BASE_PATH = path\n",
        "\n",
        "#path.ls()\n",
        "#(path/'train').ls()\n",
        "\n",
        "#torch.set_printoptions(threshold=10_000)\n",
        "\n",
        "\n",
        "# make two lists, containing all the 3's and 7's in tensor format\n",
        "three_tensors = [tensor(Image.open(o)) for o in (path/'train'/'3').ls().sorted()]\n",
        "seven_tensors = [tensor(Image.open(o)) for o in (path/'train'/'7').ls().sorted()]\n",
        "\n",
        "# combine (stack) the images into 3 dimensional tensors\n",
        "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
        "stacked_threes = torch.stack(three_tensors).float()/255\n",
        "\n",
        "\n",
        "# Objective: Take a input image and output a classification of whether it is a 3 or a 7\n",
        "# i.e: we use training images as our inputs and the 3 or 7 folder name as the target. We fit a\n",
        "# equation to this, adjusting the weights using gradient descent and measuring improvement using\n",
        "# a loss function\n",
        "\n",
        "# Stated differently, we are representing an image as a array where is component is a number\n",
        "# representing the value of a pixel.\n",
        "# We already know the classification of each image (since this is training data) and thus we\n",
        "# try to fit an equation which takes the image data (i.e: array) and outputs a value representing that\n",
        "# classification.\n",
        "\n",
        "\n",
        "# combine all the images into a single tensor. Each image is converted from a 28x28 matrix to a 1x784 vector\n",
        "# pytorch view function changes the same of a tensor\n",
        "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
        "train_y = tensor([1]*len(three_tensors) + [0]*len(seven_tensors)).unsqueeze(1)\n",
        "\n",
        "\n",
        "# start with random weights\n",
        "# we have a weight for each pixel (ie 784 weights)\n",
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
        "\n",
        "# weights = init_params((28*28,1))\n",
        "# bias = init_params(1)\n",
        "\n",
        "# preds = train_x @ weights + bias\n",
        "\n",
        "\n",
        "# # We can (arbitarily) say that predictions > 0 represent a 3 and predictions <= 0 represent a 1\n",
        "# # By comparing each of the predictions to the actual across the whole training set, we can calculate\n",
        "# # an accuracy for this set of weights against the entire training set.\n",
        "\n",
        "# corrects = (preds>0.0).float() == train_y\n",
        "# accuracy = corrects.float().mean().item()\n",
        "# # print(\"accuracy: \", accuracy)\n",
        "\n",
        "\n",
        "# with torch.no_grad(): weights[0] *= 1.0001\n",
        "# preds = train_x @ weights + bias\n",
        "# corrects = (preds>0.0).float() == train_y\n",
        "# accuracy = corrects.float().mean().item()\n",
        "# #print(\"accuracy: \", accuracy)\n",
        "\n",
        "\n",
        "# accuracy is a poor choice for our loss function as it is generally constant (0 or 1) everywhere except\n",
        "# right at the threshold\n",
        "# We need a loss function which accepts our predictions (not the actual images), the targets (i.e: the Y labels),\n",
        "# and returns a better (lower) loss if the predictions are closer to the targets\n",
        "\n",
        "# where the target is 1 (i.e.: the image is actually a 3) we return the distance between 1 and the prediction\n",
        "# else the target must be 0 (i.e.: the image is a 7) so we return the distance between 0 and the prediction\n",
        "#def minst_loss(predictions, targets):\n",
        "#  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "# note however, that our predictions may not be between 0 and 1 (as the above loss function assumes)\n",
        "# The Sigmoid function transforms any number in range -infinity to +infinity into the range 0 to 1.\n",
        "# PyTorch includes an optimised version of Sigmoid\n",
        "def minst_loss(predictions, targets):\n",
        "  predictions = predictions.sigmoid()\n",
        "  return torch.where(targets==1, 1-predictions, predictions).mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Dataset stores the samples and their corresponding labels\n",
        "# combine X and Y into a list of tuples ..\n",
        "# zip function takes two iterators (x and y) and returns a separate iterator\n",
        "# which returns tuples of the paired elements in x and y\n",
        "\n",
        "train_dset = list(zip(train_x, train_y))\n",
        "\n",
        "# Note on 'batches':\n",
        "# We typically don't want to use the entire training set each epoch. Too few training examples\n",
        "# will result in a poor fit while too many will be slow and potentially overload the GPU\n",
        "# the DataLoader class provided by PyTorch/FastAI will randomise the training data and create mini-batches\n",
        "dl = DataLoader(train_dset, batch_size=256, shuffle=True)\n",
        "\n",
        "# lets define the model as a separate function:\n",
        "def myModel(xb):\n",
        "  return xb @ weights + bias\n",
        "\n",
        "def printAccuracy(y_pred,y):\n",
        "  corrects = (y_pred>0.0).float() == y\n",
        "  accuracy = corrects.float().mean().item()\n",
        "  print(\"accuracy: \", accuracy)\n",
        "\n",
        "\n",
        "weights = init_params((28*28,1))\n",
        "bias = init_params(1)\n",
        "\n",
        "lr = 1\n",
        "\n",
        "\n",
        "# for x,y in dl:\n",
        "\n",
        "for i in range (50):\n",
        "\n",
        "  x,y = next(iter(dl))\n",
        "  preds = myModel(x)\n",
        "  loss = minst_loss(preds, y)\n",
        "  #print(\"loss: \", loss)\n",
        "  loss.backward()\n",
        "  printAccuracy(preds, y)\n",
        "\n",
        "  for p in weights, bias:\n",
        "    p.data -= p.grad*lr\n",
        "    p.grad.zero_()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NZ2eZi_mokth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cuOwOxWfs6Y2"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMieTvFMrciH60DorH1LuPd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}